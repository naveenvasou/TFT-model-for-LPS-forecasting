{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monsoon LPS Position Forecasting with Temporal Fusion Transformer\n",
    "\n",
    "This notebook loads monsoon Low Pressure System (LPS) track data, applies preprocessing including background variable integration and rolling means, and trains a Temporal Fusion Transformer (TFT) model to forecast LPS positions (Latitude and Longitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import warnings\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Import the custom model class\n",
    "from models.PositionForecasting import LPSPositionForecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Merge LPS Track Data with Background Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load core LPS dataset\n",
    "data = pd.read_csv(\"processed/all-lps-dataframe.csv\").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Load background environment variables from separate files\n",
    "bg_data = pd.read_csv(\"processed/data_with_bg.csv\").drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])\n",
    "uv_bg = pd.read_csv(\"/kaggle/input/u-v-bg/U-V-bg.csv\")\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "data['Genesis_Date'] = pd.to_datetime(data['Genesis_Date'])\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "\n",
    "# Merge background variables into main dataframe\n",
    "data[\"Q850_bg\"] = bg_data[\"Q850_bg\"]\n",
    "data[\"VS_bg\"] = bg_data[\"VS_bg\"]\n",
    "data[\"u_bg_250_850\"] = uv_bg[\"u_bg_250_850\"]\n",
    "data[\"u_bg_300_700\"] = uv_bg[\"u_bg_300_700\"]\n",
    "data[\"u_bg_400_600\"] = uv_bg[\"u_bg_400_600\"]\n",
    "data[\"v_bg_250_850\"] = uv_bg[\"v_bg_250_850\"]\n",
    "data[\"v_bg_300_700\"] = uv_bg[\"v_bg_300_700\"]\n",
    "data[\"v_bg_400_600\"] = uv_bg[\"v_bg_400_600\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Time Index and Apply Rolling Mean to Key Columns\n",
    "This helps smooth out short-term fluctuations and captures broader trends in variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time index per track to allow temporal encoding\n",
    "time_idx = []\n",
    "for i in range(1, len(data.groupby(\"id\").count()) + 1):\n",
    "    for j in range(0, data.groupby(\"id\").count()[\"Genesis_Date\"][i]):\n",
    "        time_idx.append(j)\n",
    "data[\"time_idx\"] = time_idx\n",
    "\n",
    "# Apply rolling mean for smoothing key dynamic variables\n",
    "rolling_columns = ['Latitude', 'Longitude', 'mslp', 'ls_ratio',\n",
    "       'VO550', 'VO750', 'VO850', 'PV', 'Q850', 'Q850_grad', 'Q2', 'US_850',\n",
    "       'UN_850', 'VE_850', 'VW_850', 'T2', 'Z_tilt', 'integrated_mse', 'Z250',\n",
    "       'Z550', 'Z850', 'RF']\n",
    "\n",
    "window_size = 6  # hours\n",
    "data_rolling = data.groupby('id')[rolling_columns].rolling(window=window_size, min_periods=1).mean().reset_index(drop=True)\n",
    "data[rolling_columns] = data_rolling[rolling_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Tracks to a Maximum Length of 5 Days (120 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum number of hourly steps to 5 days (8 * 24)\n",
    "max_rows = 8 * 24\n",
    "\n",
    "# Function to truncate longer tracks\n",
    "def process_track(track):\n",
    "    track_length = len(track)\n",
    "    if track_length > max_rows:\n",
    "        track = track.iloc[:max_rows]\n",
    "    return track\n",
    "\n",
    "# Apply track truncation\n",
    "data = data.groupby('id', group_keys=False).apply(process_track)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Position Forecasting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for model input\n",
    "unknown_variables = [\"Latitude\", \"Longitude\", \"mslp\", 'ls_ratio', 'VO850', \"PV\", \"T2\", \"Q850\",\n",
    "                     \"Q2\", \"UN_850\", \"US_850\", \"VE_850\", \"RF\"]\n",
    "max_prediction_length = 5 * 24  # 5 days\n",
    "max_encoder_length = 24  # use first 24 hours as input\n",
    "bg_data = [\"Q850_bg\", \"VS_bg\"]\n",
    "\n",
    "# Instantiate the model class with processed data and configuration\n",
    "postion_tft_model = LPSPositionForecasting(\n",
    "    data=data,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    unknown_variables=unknown_variables,\n",
    "    bg_data=bg_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train both latitude and longitude prediction models\n",
    "postion_tft_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "Evaluate the trained model on validation/test dataset to understand the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Latitude and Longitude predictions\n",
    "postion_tft_model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
